# ClotoCore Project Vision

> **"Neuro-Sama for Everyone"**
> 高度なAIキャラクターを、GUIで誰でも構築・操作できるプラットフォーム

---

## 1. ClotoCoreとは何か

ClotoCoreは、**AIコンテナ**と**プラグインセット**の組み合わせにより、
Neuro-Samaのような極めて高度なAIを、質の高いGUIベースで構築・操作可能にする
Rust製オープンソースプラットフォームである。

チャットボットではない。AIアシスタントでもない。
**人格を持ち、能力を持ち、ユーザーと関係を築くAIパートナー**を、
自分のマシンで、自分のデータで、自分の手で作れるようにする。

---

## 2. 競合分析：OpenClaw

| 項目 | OpenClaw | ClotoCore |
|------|----------|------|
| **言語** | TypeScript | Rust |
| **UI** | メッセージングプラットフォーム (WhatsApp, Discord等) | GUI ダッシュボード + Tauri デスクトップ |
| **設計思想** | チャットベースのパーソナルアシスタント | プラグイン構成型AIコンテナ |
| **セキュリティ** | 広範なローカル権限 | サンドボックス・パーミッション分離 |
| **拡張** | TypeScript / WASM / Skills | MCP server plugins (any language) |
| **ライセンス** | Apache 2.0 | BSL 1.1 → MIT (2028) |

### ClotoCoreの差別化ポイント

1. **Rust** — パフォーマンス、メモリ安全性、低リソース
2. **セキュリティファースト** — SafeHttpClient、MCPプロセス隔離、パーミッション分離
3. **GUIファースト** — ダッシュボードで非技術者も操作可能
4. **AIコンテナ** — パッケージ化された人格・能力セットという独自概念

---

## 3. ターゲットユーザー

### 層1: カジュアル層

GPT-4oを好んでいた、AIパートナーを求めるユーザー。

**求めているもの:**
- 人格のあるAI、感情的繋がり、ビジュアル
- 技術的知識なしで使えるインターフェース
- プライバシー（データが外部に出ない安心感）

**ClotoCoreが提供するもの:**
- プリセット「AIコンテナ」をワンクリックでインストール
- GUIでパラメータ調整（性格、声、見た目）
- ダッシュボードからリアルタイム会話

**メッセージ:**
> *「自分だけのAIパートナーを、自分のPCで。データは外に出ません。」*

### 層2: 技術者層

高度なフレームワークを求める開発者・研究者。

**求めているもの:**
- 拡張可能なフレームワーク
- Rustの安全性とパフォーマンス
- プラグイン開発の自由度

**ClotoCoreが提供するもの:**
- MCP (Model Context Protocol) ベースの拡張モデル（任意言語で MCP Server を記述可能）
- イベント駆動アーキテクチャ
- セキュリティサンドボックス

**メッセージ:**
> *「セキュリティファースト。ClotoCoreはパーミッション分離とサンドボックスで設計されています。」*

---

## 4. コアコンセプト：AIコンテナ

AIコンテナとは、**プラグインセット + 人格定義 + 能力セット**を
パッケージ化した配布可能な単位である。

```
AIコンテナ = プラグインセット + 人格定義 + 能力セット

例: "Neuro風VTuber" コンテナ
├── reasoning: DeepSeek (会話エンジン)
├── vision: カメラ/画面認識プラグイン
├── personality: キャラクター定義
├── voice: TTS/STTプラグイン
└── avatar: Live2D/VRM連携プラグイン

例: "研究アシスタント" コンテナ
├── reasoning: Claude / GPT-4o
├── tools: ファイル検索、Web検索
├── personality: 学術的・正確性重視
└── memory: 長期記憶プラグイン
```

### Neuro-Samaから学ぶ設計原則

Neuro-samaのアーキテクチャ（C# + Python、複数AIサブシステムの協調）から
以下の原則をClotoCoreに適用する：

1. **複数AIサブシステムの協調** — プラグイン間のイベント連携で実現
2. **リアルタイムインタラクション** — イベント駆動アーキテクチャで実現
3. **人格の一貫性** — AIコンテナのpersonality定義で実現
4. **能力の分離** — 会話・視覚・音声を独立プラグインとして分離

---

## 5. アーキテクチャレイヤー構造

ClotoCore は「Neuro-Sama for Everyone」を5つのレイヤーで段階的に実現する。
各レイヤーは独立しており、上位レイヤーは MCP サーバーの追加で実現可能。
カーネルの大規模な変更は不要である。

```
┌─────────────────────────────────────────────────────┐
│  Layer 5: フロントエンド体験                           │
│  Live2D/VRM アバター、TTS/STT、配信連携                │
│  → MCP: mcp-servers/avatar/, mcp-servers/voice/      │
├─────────────────────────────────────────────────────┤
│  Layer 4: 感情・人格エンジン                           │
│  内部感情状態、人格の一貫性、気分変動、自発的発話         │
│  → MCP: mcp-servers/emotion/ (KS22 と連携)           │
├─────────────────────────────────────────────────────┤
│  Layer 3: リアルタイムイベント駆動                      │
│  チャット、視覚入力、音声入力への即座の反応              │
│  → 既存: SSE + MessageReceived イベント               │
│  → MCP: mcp-servers/vision/, @playwright/mcp         │
├─────────────────────────────────────────────────────┤
│  Layer 2: 自律トリガー層                              │
│  Heartbeat (定期チェック)、Cron (スケジュール実行)       │
│  → カーネル: managers/scheduler.rs (既存パターン踏襲)   │
│  → 状態永続化: KS22 MCP                              │
├─────────────────────────────────────────────────────┤
│  Layer 1: コアインフラ                      [実装済み]  │
│  Rust Kernel、Agentic Loop、MCP、KS22 記憶            │
│  アクセス制御、YOLO mode、Dashboard UI                 │
└─────────────────────────────────────────────────────┘
```

### レイヤー詳細

| Layer | 状態 | 実現方法 | カーネル変更 |
|-------|------|---------|------------|
| **L1: コアインフラ** | 実装済み | — | — |
| **L2: 自律トリガー** | 設計済み | `tokio::interval` + CronジョブDB | 最小限 (イベント型+スケジューラ追加) |
| **L3: リアルタイム駆動** | 部分実装 | MCP サーバー追加 | なし |
| **L4: 感情エンジン** | 未着手 | MCP サーバー追加 | なし |
| **L5: アバター連携** | 設計済み | MCP サーバー追加 (Sapphy V2 VRM) | なし |

### 設計原則：MCP によるレイヤー拡張

カーネルは「ルーティング + アクセス制御 + agentic loop」に徹し、
全ての能力拡張を MCP サーバーとして外部に分離する。

```
Kernel (Rust)
  │
  ├── MCP: mind.deepseek     (推論エンジン)         ← L1
  ├── MCP: mind.cerebras     (推論エンジン)         ← L1
  ├── MCP: memory.ks22       (長期記憶)             ← L1
  ├── MCP: tool.terminal     (シェル実行)           ← L1
  ├── MCP: tool.browser      (@playwright/mcp)      ← L3
  ├── MCP: sense.vision      (カメラ/画面認識)       ← L3
  ├── MCP: sense.voice       (STT 音声入力)          ← L3
  ├── MCP: persona.emotion   (感情状態管理)          ← L4
  ├── MCP: output.tts        (音声合成)             ← L5
  └── MCP: output.avatar     (VRM 制御 — Sapphy V2)  ← L5
```

この設計により:
- カーネルのコードを変更せずに能力を追加できる
- 各 MCP サーバーは任意の言語で実装可能 (Python, TypeScript, Rust 等)
- `mcp_access_control` テーブルで per-agent 権限管理が自動適用される
- コミュニティが独自の MCP サーバーを開発・共有できる

### Neuro-Sama との技術的対応関係

| Neuro-Sama (C# + Python) | ClotoCore (Rust + MCP) |
|--------------------------|----------------------|
| 複数AIサブシステムの協調 | Kernel が MCP サーバー群をオーケストレーション |
| リアルタイムインタラクション | SSE イベント + MessageReceived + Heartbeat |
| 人格の一貫性 | AIコンテナの personality 定義 + persona.emotion MCP |
| 能力の分離 | 1能力 = 1 MCP サーバー (プロセス隔離) |
| 連続的な「意識」の模倣 | L2 Heartbeat + L4 感情状態の永続化 |
| 自発的な発話・行動 | Cron トリガー + 感情エンジンの閾値判定 |

---

## 6. ロードマップ

### Layer ロードマップ

| バージョン | Layer | マイルストーン |
|-----------|-------|--------------|
| v0.3.x | L1 完成 | Agentic loop, MCP, KS22, Chat UX, Dashboard |
| v0.4.x | L2 追加 | Heartbeat/Cron スケジューラ、自律トリガー |
| v0.5.x | L3 強化 | ブラウザ自動化 (Playwright MCP)、Vision 入力 |
| v0.6+ | L4 着手 | 感情状態管理、自発的発話 |
| v1.0+ | L5 着手 | TTS/STT、アバター連携、配信統合 |

### Phase A: 短期 (1-2ヶ月) — 「見せられるもの」を作る

1. **AIコンテナ仕様を定義する** — JSON/TOML でパッケージング形式を設計
2. **デモ用コンテナを1つ作る** — DeepSeek + 簡単な人格定義 + ダッシュボード会話
3. **30秒デモ動画** — 「インストール → コンテナ選択 → 会話」のフロー
4. **ランディングページ** — 「Build your own AI partner」のメッセージ

### Phase B: 中期 (3-6ヶ月) — コミュニティを作る

5. **AIコンテナのマーケットプレイス構想** — ユーザーが作ったコンテナを共有
6. **OpenClawからの移行ガイド** — セキュリティ比較を前面に
7. **r/LocalLLaMA、Hacker Newsへの投稿** — Rust製 × セキュリティの切り口
8. **Discord コミュニティ開設**

### Phase C: 長期 — エコシステムを育てる

9. **プラグイン開発者向けSDKドキュメント**
10. **AIコンテナ作成者向けガイド** — 非プログラマでも作れるように
11. **コンテナマーケットプレイスの実装**

---

## 7. 開発方針：一人で抱えない

コアの20%を磨いて、残り80%はコミュニティに任せる設計にする。

### 自分がやること

- コアランタイム（Rust）
- AIコンテナ仕様設計
- プラグインSDK
- セキュリティモデル
- ビジョンの発信

### コミュニティに任せること

- 個々のプラグイン開発（TTS、Vision、Avatar等）
- AIコンテナの作成・共有
- ダッシュボードのUI改善
- ドキュメント翻訳・拡充
- プラットフォーム固有の対応

---

## 8. ポジショニングステートメント

**OpenClawが「チャットで指示するAIアシスタント」なら、
ClotoCoreは「GUIで構築するAIパートナー」である。**

OpenClawはメッセージングプラットフォーム上のテキストインターフェースに縛られている。
ClotoCoreは、ビジュアル・音声・人格を持つAIを、
セキュリティを担保しながらGUIで組み立てる体験を提供する。

---

## 9. Layer 5 アバターシステム：Sapphy V2

### 採用モデル

- **モデル名**: サフィー (Sapphy) V2
- **作者**: Yueou / 仮想VoidCat
- **入手先**: https://booth.pm/ja/items/3939858
- **価格**: ¥5,480 (ユーザーが個別に購入)
- **形式**: VRM, FBX (Perfect Sync 対応)
- **ライセンス**: VN3 (個人営利利用可、法人は要問い合わせ)

### モデル選定理由

| 観点 | 評価 |
|------|------|
| **世界観** | 白銀髪 + シアンアクセント + SF/サイバネティック — ClotoCore ダッシュボードの glass morphism + シアンカラーと一致 |
| **技術適合** | VRM 形式、ARKit BlendShape 52種、Lipsync 15ビセム、67,542ポリゴン — three.js + @pixiv/three-vrm で WebGL 描画可能 |
| **表情制御** | 403 BlendShape — MCP ツール `set_expression()` で豊富な表情制御が可能 |
| **ライセンス** | 個人利用で営利可、改変可、クレジット不要 — ClotoCore BSL 期間中の開発・デモに問題なし |

### アーキテクチャ

```
┌─────────────────────────────────────────────────────┐
│  Tauri WebView (three.js + @pixiv/three-vrm)        │
│  └─ VRM モデル描画 (60fps WebGL)                     │
│     ├─ BlendShape → 表情・口パク                     │
│     ├─ SpringBone → 髪・衣装の物理                   │
│     └─ Gaze → 視線追従                              │
├─────────────────────────────────────────────────────┤
│  avatar.vrm (MCP Server — Layer 5)                  │
│  Tools:                                              │
│    ├─ set_expression(emotion, intensity)             │
│    ├─ set_mouth_shape(viseme)                        │
│    ├─ set_gaze(x, y)                                │
│    ├─ play_animation(name)                           │
│    └─ set_idle_behavior(mode)                        │
├─────────────────────────────────────────────────────┤
│  連携 MCP サーバー                                    │
│    ├─ persona.emotion (L4) → 感情 → set_expression  │
│    ├─ output.tts (L5)     → 音素 → set_mouth_shape  │
│    └─ vision.gaze_webcam  → 視線 → set_gaze         │
└─────────────────────────────────────────────────────┘
```

### 配布方針

モデルファイルは有料アセットのため、リポジトリに同梱しない:

1. ユーザーが BOOTH から Sapphy V2 を購入
2. VRM ファイルを `data/avatar/` に配置
3. ClotoCore が自動検出してアバター描画を有効化

`data/avatar/` は `.gitignore` に追加。README にセットアップ手順を記載。

### 将来の拡張

- 任意の VRM モデルに差し替え可能（Sapphy V2 は推奨モデル、唯一の選択肢ではない）
- コミュニティが独自のアバター MCP サーバーを開発可能
- Live2D 対応は別の MCP サーバー (`avatar.live2d`) として追加可能

---

*Document created: 2026-02-16*
*Last updated: 2026-03-01*
